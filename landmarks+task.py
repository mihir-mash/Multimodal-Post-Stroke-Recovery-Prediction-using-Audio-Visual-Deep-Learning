# -*- coding: utf-8 -*-
"""Landmarks+task.ipynb

Automatically generated by Colab.

Original file is located at
"""

!pip install pyrealsense2

import pyrealsense2 as rs
import numpy as np

bag_path = "path_to_video.bag"

pipeline = rs.pipeline()
config = rs.config()
config.enable_device_from_file(bag_path, repeat_playback=False)

profile = pipeline.start(config)

device = profile.get_device()
playback = device.as_playback()
playback.set_real_time(False)

print("Available Streams:")
for s in profile.get_streams():
    print("Stream:", s.stream_type(),
          "Resolution:", s.as_video_stream_profile().width(), "x",
          s.as_video_stream_profile().height(),
          "FPS:", s.as_video_stream_profile().fps())

frame_count = 0
depth_frames = 0
color_frames = 0

try:
    while True:
        frames = pipeline.wait_for_frames()
        frame_count += 1

        depth = frames.get_depth_frame()
        color = frames.get_color_frame()

        if depth:
            depth_frames += 1
        if color:
            color_frames += 1

except RuntimeError:
    pass

pipeline.stop()

print("\nTotal frames:", frame_count)
print("Depth frames:", depth_frames)
print("Color frames:", color_frames)

import torch
from collections import Counter

data = torch.load("path_to_dataset.pt")

print("Keys in dataset:", data.keys())

tasks = data["tasks"]

print("\nTotal samples:", len(tasks))
print("\nFirst 15 task entries:")
for t in tasks[:15]:
    print(t)

unique_tasks = list(set(tasks))
print("\nNumber of unique tasks:", len(unique_tasks))
print("Unique tasks:", unique_tasks)

print("\nTask frequency:")
print(Counter(tasks))

import os

video_folder = "path_to_video_folder"

fine_tasks = []

for file in os.listdir(video_folder):
    if file.endswith(".avi"):
        parts = file.replace(".avi", "").split("_")

        # Extract everything after session index
        # Example: OP01_02_NSM_BIGSMILE_color
        task_parts = parts[2:-1]  # remove subject, session, and "color"
        fine_task = "_".join(task_parts)

        fine_tasks.append(fine_task)

print("Unique fine tasks:")
print(set(fine_tasks))

"""#Imp"""

import pandas as pd
import numpy as np

# Load files
slp_path = "path_to_slp_assessment"
video_info_path = "path_to_video_info"

slp_df = pd.read_excel(slp_path)
video_info_df = pd.read_excel(video_info_path)

# Compute Tot_Avg
slp_df["Tot_Avg"] = (slp_df["Tot (SLP1)"] + slp_df["Tot (SLP2)"]) / 2

# Compute min and max dynamically
min_score = slp_df["Tot_Avg"].min()
max_score = slp_df["Tot_Avg"].max()

print("Min Tot_Avg:", min_score)
print("Max Tot_Avg:", max_score)

# Compute Recovery %
slp_df["Recovery_Percent"] = (
    (max_score - slp_df["Tot_Avg"]) /
    (max_score - min_score)
) * 100

# Merge with VideoInfo to get fine task
merged_df = pd.merge(
    slp_df,
    video_info_df[["File Name", "Task", "Subtask"]],
    on="File Name",
    how="inner"
)

# Create fine task
merged_df["Fine_Task"] = merged_df["Task"] + "_" + merged_df["Subtask"]

print("\nColumns after merge:")
print(merged_df.columns)

print("\nFirst 5 rows:")
print(merged_df[["File Name", "Subject ID", "Fine_Task", "Tot_Avg", "Recovery_Percent"]].head())

print("\nTotal merged rows:", len(merged_df))
print("Unique fine tasks:", merged_df["Fine_Task"].unique())

import cv2

def sample_frames(video_path, num_frames=30):
    cap = cv2.VideoCapture(video_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    if total_frames == 0:
        cap.release()
        return None

    indices = np.linspace(0, total_frames - 1, num_frames).astype(int)

    frames = []
    for idx in indices:
        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
        ret, frame = cap.read()
        if not ret:
            cap.release()
            return None
        frames.append(frame)

    cap.release()
    return frames

!apt-get update
!apt-get install -y cmake libopenblas-dev liblapack-dev libx11-dev libgtk-3-dev
!pip install dlib

!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2
!bunzip2 shape_predictor_68_face_landmarks.dat.bz2

import os
print(os.path.exists("shape_predictor_68_face_landmarks.dat"))

import dlib

detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor("shape_predictor_68_face_landmarks.dat")

detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor("shape_predictor_68_face_landmarks.dat")

def extract_landmarks(frames):
    landmark_sequence = []

    for frame in frames:
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = detector(gray)

        if len(faces) == 0:
            return None

        shape = predictor(gray, faces[0])

        h, w = frame.shape[:2]
        landmarks = []

        for i in range(68):
            x = shape.part(i).x / w
            y = shape.part(i).y / h
            landmarks.append([x, y])

        landmark_sequence.append(landmarks)

    return np.array(landmark_sequence)  # (30, 68, 2)

import torch
import os

video_folder = "path_to_video_folder"

landmarks_list = []
labels_list = []
subjects_list = []
tasks_list = []
failed_videos = []

for _, row in merged_df.iterrows():

    filename = row["File Name"]
    subject = row["Subject ID"]
    fine_task = row["Fine_Task"]
    recovery = row["Recovery_Percent"]

    video_path = os.path.join(video_folder, filename)

    if not os.path.exists(video_path):
        failed_videos.append(filename)
        continue

    frames = sample_frames(video_path, num_frames=30)
    if frames is None:
        failed_videos.append(filename)
        continue

    landmarks = extract_landmarks(frames)
    if landmarks is None:
        failed_videos.append(filename)
        continue

    landmarks_list.append(torch.tensor(landmarks, dtype=torch.float32))
    labels_list.append(torch.tensor(recovery, dtype=torch.float32))
    subjects_list.append(subject)
    tasks_list.append(fine_task)

print("Total successful samples:", len(landmarks_list))
print("Failed videos:", len(failed_videos))
print("Failed list:", failed_videos)

"""Tried Dlib but it failed miserably"""

import os
import torch
import pandas as pd
import numpy as np

# Paths
landmark_folder = "path_to_landmark_folder"
save_path = "path_to_save_dataset"

# Load merged clinical dataframe (from previous step)
# Ensure merged_df already exists from earlier code

landmarks_list = []
labels_list = []
subjects_list = []
tasks_list = []
failed_files = []

FRAME_WIDTH = 640
FRAME_HEIGHT = 480
NUM_FRAMES = 30

def sample_landmarks_from_txt(txt_path, num_frames=30):
    df = pd.read_csv(txt_path)

    total_frames = len(df)
    if total_frames == 0:
        return None

    indices = np.linspace(0, total_frames - 1, num_frames).astype(int)
    sampled = df.iloc[indices]

    landmark_seq = []

    for _, row in sampled.iterrows():
        coords = row.values[1:]  # skip frame index
        coords = np.array(coords, dtype=np.float32)
        coords = coords.reshape(68, 2)

        # Normalize
        coords[:, 0] /= FRAME_WIDTH
        coords[:, 1] /= FRAME_HEIGHT

        landmark_seq.append(coords)

    return np.array(landmark_seq)  # (30, 68, 2)

for _, row in merged_df.iterrows():

    filename = row["File Name"]
    subject = row["Subject ID"]
    fine_task = row["Fine_Task"]
    recovery = row["Recovery_Percent"]

    txt_name = filename.replace(".avi", ".txt")
    txt_path = os.path.join(landmark_folder, txt_name)

    if not os.path.exists(txt_path):
        failed_files.append(filename)
        continue

    landmarks = sample_landmarks_from_txt(txt_path, NUM_FRAMES)
    if landmarks is None:
        failed_files.append(filename)
        continue

    landmarks_list.append(torch.tensor(landmarks, dtype=torch.float32))
    labels_list.append(torch.tensor(recovery, dtype=torch.float32))
    subjects_list.append(subject)
    tasks_list.append(fine_task)

print("Total successful samples:", len(landmarks_list))
print("Failed files:", len(failed_files))
print("Failed list:", failed_files)

dataset_v2 = {
    "landmarks": landmarks_list,
    "labels": labels_list,
    "subjects": subjects_list,
    "tasks": tasks_list
}

torch.save(dataset_v2, save_path)
print("Saved as:", save_path)

"""#Singular LOSO (test)"""

import torch

dataset_path = "path_to_dataset.pt"

data = torch.load(dataset_path)

unique_tasks = sorted(list(set(data["tasks"])))
task_to_idx = {task: idx for idx, task in enumerate(unique_tasks)}
idx_to_task = {idx: task for task, idx in task_to_idx.items()}

print("Task to Index Mapping:")
print(task_to_idx)

print("\nNumber of tasks:", len(task_to_idx))

import torch
from torch.utils.data import Dataset
import numpy as np

class StrokeLandmarkDataset(Dataset):
    def __init__(self, dataset_path, task_to_idx, augment=False):
        data = torch.load(dataset_path)

        self.landmarks = data["landmarks"]
        self.labels = data["labels"]
        self.subjects = data["subjects"]
        self.tasks = data["tasks"]
        self.task_to_idx = task_to_idx
        self.augment = augment

    def __len__(self):
        return len(self.landmarks)

    def add_noise(self, x):
        noise = torch.randn_like(x) * 0.01
        return torch.clamp(x + noise, 0.0, 1.0)

    def __getitem__(self, idx):
        x = self.landmarks[idx]
        y = self.labels[idx]
        task = self.task_to_idx[self.tasks[idx]]

        if self.augment:
            x = self.add_noise(x)

        return {
            "landmarks": x,              # (30, 68, 2)
            "label": y.unsqueeze(0),     # (1,)
            "task": torch.tensor(task),
            "subject": self.subjects[idx]
        }

import torch.nn as nn
import torch

class AttentionPooling(nn.Module):
    def __init__(self, input_dim):
        super().__init__()
        self.attn = nn.Linear(input_dim, 1)

    def forward(self, x):
        weights = torch.softmax(self.attn(x), dim=1)
        return torch.sum(weights * x, dim=1)

class LandmarkTaskModel(nn.Module):
    def __init__(self, num_tasks):
        super().__init__()

        self.lstm = nn.LSTM(
            input_size=136,
            hidden_size=64,
            batch_first=True,
            bidirectional=True
        )

        self.attention = AttentionPooling(128)

        self.task_embedding = nn.Embedding(num_tasks, 16)

        self.fusion = nn.Sequential(
            nn.Linear(128 + 16, 64),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(64, 1)
        )

    def forward(self, landmarks, task_ids):
        B = landmarks.size(0)

        x = landmarks.view(B, 30, -1)  # (B,30,136)

        lstm_out, _ = self.lstm(x)
        temporal_feat = self.attention(lstm_out)

        task_feat = self.task_embedding(task_ids)

        fused = torch.cat([temporal_feat, task_feat], dim=1)
        out = self.fusion(fused)

        return out

def get_loso_split(dataset, test_subject):
    train_indices = []
    test_indices = []

    for i in range(len(dataset)):
        if dataset.subjects[i] == test_subject:
            test_indices.append(i)
        else:
            train_indices.append(i)

    return train_indices, test_indices

import torch
from torch.utils.data import DataLoader, Subset
import torch.nn as nn
import numpy as np

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

dataset_path = "path_to_dataset.pt"

data = torch.load(dataset_path)
unique_tasks = sorted(list(set(data["tasks"])))
task_to_idx = {task: idx for idx, task in enumerate(unique_tasks)}

dataset = StrokeLandmarkDataset(dataset_path, task_to_idx, augment=True)

test_subject = "OP01"   # change later if needed

train_idx, test_idx = get_loso_split(dataset, test_subject)

train_loader = DataLoader(Subset(dataset, train_idx), batch_size=8, shuffle=True)
test_loader = DataLoader(Subset(dataset, test_idx), batch_size=8, shuffle=False)

model = LandmarkTaskModel(num_tasks=len(task_to_idx)).to(device)

criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

EPOCHS = 40

for epoch in range(EPOCHS):
    model.train()
    train_loss = 0

    for batch in train_loader:
        landmarks = batch["landmarks"].to(device)
        labels = batch["label"].to(device)
        tasks = batch["task"].to(device)

        preds = model(landmarks, tasks)
        loss = criterion(preds, labels)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        train_loss += loss.item()

    print(f"Epoch {epoch+1}/{EPOCHS} - Train Loss: {train_loss/len(train_loader):.4f}")

model.eval()
all_preds = []
all_labels = []

with torch.no_grad():
    for batch in test_loader:
        landmarks = batch["landmarks"].to(device)
        labels = batch["label"].to(device)
        tasks = batch["task"].to(device)

        preds = model(landmarks, tasks)

        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

all_preds = np.array(all_preds).flatten()
all_labels = np.array(all_labels).flatten()

mae = np.mean(np.abs(all_preds - all_labels))
print("\nTest Subject:", test_subject)
print("MAE:", mae)

"""#Full LOSO"""

import torch
import torch.nn as nn
import numpy as np
from torch.utils.data import Dataset, DataLoader, Subset

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

dataset_path = "path_to_dataset.pt"
data = torch.load(dataset_path)

unique_tasks = sorted(list(set(data["tasks"])))
task_to_idx = {task: idx for idx, task in enumerate(unique_tasks)}

class StrokeLandmarkDataset(Dataset):
    def __init__(self, data, task_to_idx, augment=False):
        self.landmarks = data["landmarks"]
        self.labels = data["labels"]
        self.subjects = data["subjects"]
        self.tasks = data["tasks"]
        self.task_to_idx = task_to_idx
        self.augment = augment

    def __len__(self):
        return len(self.landmarks)

    def add_noise(self, x):
        noise = torch.randn_like(x) * 0.01
        return torch.clamp(x + noise, -1.0, 1.0)

    def preprocess(self, x):
        # x shape: (30, 68, 2)

        # Center each frame
        centroid = x.mean(dim=1, keepdim=True)
        x_centered = x - centroid

        # Temporal derivatives
        dx = torch.zeros_like(x_centered)
        dx[1:] = x_centered[1:] - x_centered[:-1]

        # Concatenate position + velocity
        x_combined = torch.cat([x_centered, dx], dim=2)  # (30, 68, 4)

        return x_combined

    def __getitem__(self, idx):
        x = self.landmarks[idx]
        y = self.labels[idx]
        task = self.task_to_idx[self.tasks[idx]]

        x = self.preprocess(x)

        if self.augment:
            x = self.add_noise(x)

        return {
            "landmarks": x,
            "label": y.unsqueeze(0),
            "task": torch.tensor(task),
            "subject": self.subjects[idx]
        }

class LandmarkEncoder(nn.Module):
    def __init__(self):
        super().__init__()

        self.lstm = nn.LSTM(
            input_size=68*4,   # position + velocity
            hidden_size=96,
            batch_first=True,
            bidirectional=True
        )

        self.attention = AttentionPooling(192)
        self.norm = nn.LayerNorm(192)   # IMPORTANT for multimodal stability

    def forward(self, x):
        B = x.size(0)
        x = x.view(B, 30, -1)

        lstm_out, _ = self.lstm(x)
        emb = self.attention(lstm_out)
        emb = self.norm(emb)

        return emb   # (B, 192)

class TaskEncoder(nn.Module):
    def __init__(self, num_tasks):
        super().__init__()
        self.embedding = nn.Embedding(num_tasks, 16)
        self.norm = nn.LayerNorm(16)

    def forward(self, task_ids):
        task_emb = self.embedding(task_ids)
        task_emb = self.norm(task_emb)
        return task_emb

class RegressionHead(nn.Module):
    def __init__(self, input_dim):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, 96),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(96, 1)
        )

    def forward(self, x):
        return self.net(x)

class LandmarkTaskModel(nn.Module):
    def __init__(self, num_tasks):
        super().__init__()

        self.landmark_encoder = LandmarkEncoder()
        self.task_encoder = TaskEncoder(num_tasks)

        self.head = RegressionHead(192 + 16)

    def forward(self, landmarks, task_ids):
        geom_emb = self.landmark_encoder(landmarks)
        task_emb = self.task_encoder(task_ids)

        fused = torch.cat([geom_emb, task_emb], dim=1)
        return self.head(fused)

class AttentionPooling(nn.Module):
    def __init__(self, input_dim):
        super().__init__()
        self.attn = nn.Linear(input_dim, 1)

    def forward(self, x):
        weights = torch.softmax(self.attn(x), dim=1)
        return torch.sum(weights * x, dim=1)

def get_loso_split(dataset, test_subject):
    train_idx = []
    test_idx = []

    for i in range(len(dataset)):
        if dataset.subjects[i] == test_subject:
            test_idx.append(i)
        else:
            train_idx.append(i)

    return train_idx, test_idx

global_preds = []
global_labels = []

dataset = StrokeLandmarkDataset(data, task_to_idx, augment=True)

subjects = sorted(list(set(dataset.subjects)))
mae_results = {}

EPOCHS = 40
BATCH_SIZE = 8
LR = 1e-3
PATIENCE = 6

for test_subject in subjects:

    train_idx, test_idx = get_loso_split(dataset, test_subject)

    train_loader = DataLoader(Subset(dataset, train_idx), batch_size=BATCH_SIZE, shuffle=True)
    test_loader = DataLoader(Subset(dataset, test_idx), batch_size=BATCH_SIZE, shuffle=False)

    model = LandmarkTaskModel(num_tasks=len(task_to_idx)).to(device)
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=LR)

    best_val_loss = float("inf")
    patience_counter = 0

    for epoch in range(EPOCHS):
        model.train()
        train_loss = 0

        for batch in train_loader:
            landmarks = batch["landmarks"].to(device)
            labels = batch["label"].to(device)
            tasks = batch["task"].to(device)

            preds = model(landmarks, tasks)
            loss = criterion(preds, labels)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            train_loss += loss.item()

        # Early stopping based on train loss
        avg_train_loss = train_loss / len(train_loader)

        if avg_train_loss < best_val_loss:
            best_val_loss = avg_train_loss
            patience_counter = 0
        else:
            patience_counter += 1

        if patience_counter >= PATIENCE:
            break

    # Evaluation
    model.eval()
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for batch in test_loader:
            landmarks = batch["landmarks"].to(device)
            labels = batch["label"].to(device)
            tasks = batch["task"].to(device)

            preds = model(landmarks, tasks)

            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

            global_preds.extend(all_preds)
            global_labels.extend(all_labels)

    all_preds = np.array(all_preds).flatten()
    all_labels = np.array(all_labels).flatten()

    mae = np.mean(np.abs(all_preds - all_labels))
    mae_results[test_subject] = mae

    print(f"{test_subject} MAE: {mae:.4f}")

mae_values = list(mae_results.values())

print("\nPer-Subject MAE:")
print(mae_results)

print("\nMean MAE:", np.mean(mae_values))
print("Std MAE:", np.std(mae_values))

from sklearn.metrics import r2_score
from scipy.stats import pearsonr

r2 = r2_score(all_labels, all_preds)
corr, _ = pearsonr(all_labels, all_preds)

print("RÂ²:", r2)
print("Pearson correlation:", corr)

import numpy as np
from sklearn.metrics import confusion_matrix, classification_report

global_preds = np.array(global_preds)
global_labels = np.array(global_labels)

threshold = 60

true_binary = (global_labels >= threshold).astype(int)
pred_binary = (global_preds >= threshold).astype(int)

cm = confusion_matrix(true_binary, pred_binary)

print("Confusion Matrix:")
print(cm)

tn, fp, fn, tp = cm.ravel()

accuracy = (tp + tn) / (tp + tn + fp + fn)
sensitivity = tp / (tp + fn)  # recall for recovered
specificity = tn / (tn + fp)

print("\nClinical Metrics (Threshold = 60%)")
print("Accuracy:", accuracy)
print("Sensitivity (Recovered detection):", sensitivity)
print("Specificity (Impaired detection):", specificity)

print("\nFull Classification Report:")
print(classification_report(true_binary, pred_binary))

torch.save(model.landmark_encoder.state_dict(), "path_to_save_landmark_encoder.pt")
torch.save(model.task_encoder.state_dict(), "path_to_save_task_encoder.pt")

